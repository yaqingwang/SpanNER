{'silent': False, 'debug': False, 'data_parallel': False, 'use_attention': True, 'zero_shot': False, 'no_cuda': False, 'top_k': 10, 'seed': 42, 'zeshel': True, 'max_seq_length': 256, 'max_context_length': 128, 'max_cand_length': 128, 'path_to_model': None, 'gpu_ids': '0', 'bert_model': 'bert-base-uncased', 'pull_from_layer': -1, 'lowercase': True, 'context_key': 'context', 'title_key': 'entity', 'out_dim': 1, 'add_linear': False, 'entity_inference': False, 'data_path': './dataset/conll03_gold/tokenized_uncased_10', 'output_path': './experiments/conll03_gold/bert-base-uncased_true_all_avg_linear_128_true_false_bert_base_qa_linear', 'mention_aggregation_type': 'all_avg_linear', 'no_mention_bounds': True, 'mention_scoring_method': 'qa_linear', 'max_mention_length': 10, 'evaluate': False, 'output_eval_file': None, 'train_batch_size': 16, 'eval_batch_size': 16, 'max_grad_norm': 1.0, 'learning_rate': 1e-05, 'num_train_epochs': 1000, 'print_interval': 10, 'eval_interval': 20, 'save_interval': 1, 'warmup_proportion': 0.0, 'gradient_accumulation_steps': 1, 'type_optimization': 'all_encoder_layers', 'shuffle': True, 'start_idx': None, 'end_idx': None, 'last_epoch': -1, 'path_to_trainer_state': None, 'dont_distribute_train_samples': True, 'freeze_cand_enc': True, 'load_cand_enc_only': True, 'cand_enc_path': './dataset/conll03_gold/tokenized_uncased_10/wiki_base_seq_embedding_label.pt', 'cand_token_ids_path': './dataset/conll03_gold/tokenized_uncased_10/wiki_tokenized_label.pt', 'index_path': 'models/faiss_hnsw_index.pkl', 'adversarial_training': False, 'get_losses': True}